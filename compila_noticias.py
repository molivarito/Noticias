# --- Env√≠o de res√∫menes por email ---
import subprocess
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

# --- Para generaci√≥n de res√∫menes autom√°ticos con IA Generativa ---
import argparse # Importar argparse
import google.generativeai as genai
import os
import time

# --- Para parseo de feeds RSS y manejo de fechas ---
import feedparser
from datetime import datetime, timedelta, timezone

# --- Para extracci√≥n de contenido de art√≠culos ---
from newspaper import Article

# --- SSL Configuration for macOS and certifi ---
import ssl
import certifi
# --- Para cargar variables de entorno desde .env (√∫til para desarrollo local) ---
from dotenv import load_dotenv

load_dotenv() # Carga variables desde un archivo .env en el mismo directorio

try:
    # Configure Python's SSL context to use certifi's CA bundle.
    ssl_context = ssl.create_default_context(cafile=certifi.where())
    ssl._create_default_https_context = lambda: ssl_context
    print("‚úÖ SSL context configured to use certifi's CA bundle.")
except Exception as e:
    print(f"‚ö†Ô∏è Warning: Could not configure SSL context with certifi: {e}")
    print("   Attempting to proceed without custom SSL context for certifi. SSL errors might persist.")

# --- Constantes ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__)) # Directorio donde se encuentra el script
FUENTES_RSS_JSON_PATH = os.path.join(SCRIPT_DIR, "fuentes_rss.json")
DEFAULT_HOURS_AGO = 24
DEFAULT_WEEKLY_HOURS = 7 * 24 # 7 d√≠as en horas
USER_AGENT = "NewsAggregatorBot/1.0 (+http://example.com/botinfo)"
MAX_ARTICLES_TO_SUMMARIZE_PER_CATEGORY = 5 # L√≠mite de art√≠culos a resumir por categor√≠a

# Leer la URL base del servidor desde una variable de entorno.
# El workflow de GitHub Actions la proveer√° desde un secret o un valor por defecto.
# Para GitHub Pages, el workflow pasa la URL completa.
github_repo_owner = os.getenv("GITHUB_REPOSITORY_OWNER")
github_repo_name = os.getenv("GITHUB_REPOSITORY_NAME")

if github_repo_owner and github_repo_name:
    default_gh_pages_url = f"https://{github_repo_owner}.github.io/{github_repo_name}/"
else:
    default_gh_pages_url = "https://tu-usuario.github.io/tu-repositorio/" # Placeholder si no se ejecuta en Actions
BASE_WEB_URL = os.getenv("BASE_WEB_URL", default_gh_pages_url)

import json

# --- Funci√≥n para cargar fuentes desde JSON ---
def cargar_fuentes_desde_json():
    try:
        with open(FUENTES_RSS_JSON_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå Error CR√çTICO: No se encontr√≥ el archivo de fuentes RSS en {FUENTES_RSS_JSON_PATH}")
        print("   Aseg√∫rate de que el archivo 'fuentes_rss.json' exista en el mismo directorio que el script.")
        exit(1) # Termina el script si el archivo de fuentes no existe.
    except json.JSONDecodeError as e:
        print(f"‚ùå Error CR√çTICO: El archivo de fuentes RSS en {FUENTES_RSS_JSON_PATH} no es un JSON v√°lido: {e}")
        exit(1) # Termina el script si el JSON es inv√°lido.

# --- Funci√≥n para resumir art√≠culos usando Gemini ---
def resumir_y_puntuar_con_gemini(model, titulo, contenido, categoria):
    """
    Resume un art√≠culo y le asigna una puntuaci√≥n de relevancia utilizando la API de Gemini.
    El 'model' de Gemini debe ser preinicializado y pasado como argumento.
    Devuelve un diccionario con 'teaser_sentence', 'resumen', 'relevancia_score', 'relevancia_justificacion' o None.
    """
    prompt = f"""
Analiza el siguiente art√≠culo.
T√≠tulo: {titulo}
Contenido:
{contenido}

Tu tarea es:
1.  Crea una frase √∫nica y concisa (m√°ximo 15-25 palabras) que sirva como un "gancho" o "teaser" del art√≠culo.
2.  Resume brevemente el art√≠culo en espa√±ol (aproximadamente 100-150 palabras). Aseg√∫rate de que el resumen sea un texto plano v√°lido, escapando correctamente cualquier car√°cter especial si es necesario para JSON.
3.  Eval√∫a la relevancia e inter√©s general del art√≠culo para un lector interesado en la categor√≠a '{categoria.replace('_', ' ').title()}', en una escala num√©rica del 1 (poco relevante/interesante) al 10 (muy relevante/interesante).
4.  Proporciona una frase breve justificando tu puntuaci√≥n de relevancia. Aseg√∫rate de que la justificaci√≥n sea un texto plano v√°lido, escapando correctamente cualquier car√°cter especial si es necesario para JSON.

Proporciona tu respuesta ESTRICTAMENTE en el siguiente formato JSON. No incluyas ning√∫n texto antes o despu√©s del bloque JSON.
{{
  "teaser_sentence": "Tu frase gancho aqu√≠...",
  "resumen": "Tu resumen aqu√≠...",
  "relevancia_score": <tu puntuaci√≥n num√©rica entera entre 1 y 10>,
  "relevancia_justificacion": "Una frase breve justificando tu puntuaci√≥n de relevancia."
}}
"""
    try:
        print(f"    üìù Solicitando resumen y puntuaci√≥n para: {titulo} (Categor√≠a: {categoria})")
        response = model.generate_content(prompt)
        raw_text = response.text

        # Intenta extraer el JSON incluso si hay texto adicional antes/despu√©s
        json_start = raw_text.find('{')
        json_end = raw_text.rfind('}')
        if json_start != -1 and json_end != -1 and json_end > json_start:
            json_text = raw_text[json_start:json_end+1]
        else:
            json_text = raw_text # Asume que es JSON si no se encuentran los delimitadores

        return json.loads(json_text)
    except json.JSONDecodeError as e:
        print(f"    ‚ùå Error al decodificar JSON de Gemini para '{titulo}': {e}. Respuesta recibida: {raw_text[:200]}...")
        return None
    except Exception as e:
        print(f"    ‚ùå Error al resumir y puntuar con Gemini para '{titulo}': {e}")
        return None


def extraer_contenido(url):
    try:
        headers = {
            'User-Agent': USER_AGENT
        }
        articulo = Article(url, browser_user_agent=USER_AGENT, headers=headers)
        articulo.download()
        articulo.parse()
        return articulo.text
    except Exception as e:
        print(f"Error al extraer contenido del art√≠culo ({url}): {e}")
        return ""


def obtener_articulos_recientes(rss_url, horas):
    """
    Obtiene art√≠culos de un feed RSS publicados en las √∫ltimas 'horas'.
    """
    print(f"\nFetching RSS feed: {rss_url}")
    feed = feedparser.parse(rss_url, agent=USER_AGENT)
    articulos_recientes = []

    if feed.bozo:
        bozo_type = feed.bozo_exception.__class__.__name__
        bozo_message = str(feed.bozo_exception)
        print(f"‚ö†Ô∏è Warning: Feed {rss_url} may be malformed. Type: {bozo_type}, Message: {bozo_message}")
    
    if not feed.entries:
        print(f"‚ÑπÔ∏è No entries found in feed: {rss_url}")
        return articulos_recientes

    print(f"  Found {len(feed.entries)} total entries in {rss_url}.")

    ahora_utc = datetime.now(timezone.utc)
    limite_tiempo_utc = ahora_utc - timedelta(hours=horas)

    for entry in feed.entries:
        fecha_articulo_utc = None
        date_struct = None

        if hasattr(entry, 'published_parsed') and entry.published_parsed:
            date_struct = entry.published_parsed
        elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
            date_struct = entry.updated_parsed
        
        if date_struct:
            try:
                fecha_articulo_naive = datetime(
                    date_struct.tm_year, date_struct.tm_mon, date_struct.tm_mday,
                    date_struct.tm_hour, date_struct.tm_min, date_struct.tm_sec,
                )
                fecha_articulo_utc = fecha_articulo_naive.replace(tzinfo=timezone.utc)

                if fecha_articulo_utc > limite_tiempo_utc:
                    articulos_recientes.append({
                        "titulo": entry.get("title", "[sin t√≠tulo]"),
                        "link": entry.get("link", "[sin link]"),
                        "fecha_obj": fecha_articulo_utc, # datetime object para ordenar
                        "fecha_str": fecha_articulo_utc.strftime("%Y-%m-%d %H:%M:%S UTC") # string para mostrar
                    })
            except Exception as e:
                print(f"    - Error processing date for entry '{entry.get('title', '[sin t√≠tulo]')}': {e}")
            
    print(f"  Found {len(articulos_recientes)} recent articles from {rss_url} (last {horas} hours).")
    return articulos_recientes

def procesar_y_resumir_articulos(fuentes, gemini_model, horas_a_revisar):
    def generate_html_content(processed_articles_by_category, report_type, generation_timestamp_str):
        # Iconos Unicode para categor√≠as (puedes personalizarlos)
        category_icons = {
            "internacional": "üåç",
            "nacional": "üá®üá±", # O un icono m√°s gen√©rico como üì∞
            "opinion_ensayo": "‚úçÔ∏è",
            "ciencia_tecnologia": "üî¨",
            "cultura_arte": "üé®",
            "default": "üîπ" # Icono por defecto
        }

        html_content = f"""
    <!DOCTYPE html>
    <html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700&family=Roboto:wght@400;700&display=swap" rel="stylesheet">
        <title>Resumen {report_type.title()} de Noticias</title>
        <style>
            body {{ 
                font-family: 'Roboto', sans-serif; 
                line-height: 1.6; margin: 0; padding: 20px; 
                background-color: #f4f7f6; /* Fondo ligeramente m√°s c√°lido */
                color: #333; 
            }}
            .container {{ max-width: 900px; margin: 30px auto; background-color: #ffffff; padding: 30px; border-radius: 10px; box-shadow: 0 6px 12px rgba(0,0,0,0.08); }}
            h1 {{ font-family: 'Montserrat', sans-serif; color: #2c3e50; text-align: center; margin-bottom: 15px; font-weight: 700; font-size: 2.2em; }}
            .report-timestamp {{ text-align: center; font-size: 0.9em; color: #555; margin-top: -10px; margin-bottom: 35px; }}
            h2 {{ font-family: 'Montserrat', sans-serif; color: #34495e; border-bottom: 3px solid #1abc9c; /* Color de acento */ padding-bottom: 12px; margin-top: 40px; margin-bottom: 25px; font-weight: 600; font-size: 1.8em; }}
            details {{ background-color: #fdfdfd; border: 1px solid #e0e0e0; border-radius: 8px; margin-bottom: 20px; padding: 20px; box-shadow: 0 3px 6px rgba(0,0,0,0.04); transition: box-shadow 0.3s ease; }}
            details:hover {{ box-shadow: 0 5px 10px rgba(0,0,0,0.06); }}
            details[open] {{ background-color: #ffffff; border-left: 5px solid #1abc9c; /* Color de acento al abrir */ }}
            summary {{ font-family: 'Montserrat', sans-serif; font-weight: 600; cursor: pointer; color: #2980b9; /* Azul m√°s vibrante */ font-size: 1.15em; margin-bottom: 8px; list-style-position: inside; outline: none; }}
            summary:hover {{ color: #1f618d; }}
            .article-content-wrapper {{ padding-top: 10px; }}
            .article-title {{ font-size: 1.15em; font-weight: bold; color: #343a40; margin-bottom: 5px; }}
            .article-meta {{ font-size: 0.85em; color: #6c757d; margin-bottom: 8px; }}
            .article-summary {{ margin-top: 10px; color: #495057; }}
            a {{ color: #007bff; text-decoration: none; }}
            a:hover {{ text-decoration: underline; }}
            .no-articles {{ font-style: italic; color: #6c757d; margin-left: 10px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Resumen {report_type.title()} de Noticias</h1>
            <p class="report-timestamp">Generado el: {generation_timestamp_str}</p>
            """
        
        if not processed_articles_by_category:
            html_content += "<p class='no-articles'><i>No se procesaron art√≠culos para ninguna categor√≠a.</i></p>"
        else:
            for categoria, articulos_procesados_list in processed_articles_by_category.items():
                icon = category_icons.get(categoria, category_icons["default"])
                html_content += f"<h2>{icon} {categoria.replace('_', ' ').title()}</h2>"
                
                if not articulos_procesados_list:
                    html_content += f"<p class='no-articles'><i>No se encontraron art√≠culos procesados para la categor√≠a {icon} {categoria.replace('_', ' ').title()}.</i></p>"
                else:
                    for item_procesado in articulos_procesados_list:
                        articulo_info = item_procesado["info"]
                        resumen_datos = item_procesado["resumen_datos"]
                        html_content += f"""
                                <details>
                                    <summary>
                                        {resumen_datos['teaser_sentence']} (Puntuaci√≥n: {resumen_datos['relevancia_score']}/10)
                                    </summary>
                                    <div class="article-content-wrapper">
                                        <p class="article-title">{articulo_info['titulo']}</p>
                                        <p class="article-meta">
                                            Fuente: {articulo_info['source_name']} | Fecha: {articulo_info.get('fecha_str', 'No disp.')} | Justificaci√≥n: {resumen_datos.get('relevancia_justificacion', 'N/A')}
                                        </p>
                                        <p class="article-summary">{resumen_datos['resumen']}</p>
                                        <a href='{articulo_info['link']}' target='_blank'>Leer m√°s en la fuente original</a>
                                    </div>
                                </details>
                        """

        html_content += """
        </div>
    </body>
    </html>
    """
        return html_content

    all_articles_by_category = {}
    for categoria, lista_fuentes in fuentes.items():
        all_articles_this_category = []
        print(f"\nüìö Recopilando art√≠culos para la categor√≠a: {categoria.replace('_', ' ').title()}")
        for fuente in lista_fuentes:
            articulos_de_fuente = obtener_articulos_recientes(fuente["url"], horas=horas_a_revisar) 
            for art in articulos_de_fuente:
                art['source_name'] = fuente['name']
                all_articles_this_category.append(art)
        all_articles_by_category[categoria] = all_articles_this_category
        print(f"  üì∞ Total de art√≠culos recientes encontrados en '{categoria.replace('_', ' ').title()}': {len(all_articles_this_category)}")

    processed_articles_by_category = {}
    any_article_processed_overall = False

    for categoria, all_articles_this_category in all_articles_by_category.items():
        print(f"\n‚ú® Procesando art√≠culos para la categor√≠a: {categoria.replace('_', ' ').title()}")
        all_articles_this_category.sort(key=lambda x: x['fecha_obj'], reverse=True)
        articles_to_summarize_for_category = all_articles_this_category[:MAX_ARTICLES_TO_SUMMARIZE_PER_CATEGORY]
        print(f"  üéØ Seleccionados para resumir en '{categoria.replace('_', ' ').title()}': {len(articles_to_summarize_for_category)} art√≠culos (l√≠mite: {MAX_ARTICLES_TO_SUMMARIZE_PER_CATEGORY})")
        articulos_procesados_final_categoria = []
        for i, articulo_para_resumir in enumerate(articles_to_summarize_for_category):
            print(f"  üîÑ Procesando ({i+1}/{len(articles_to_summarize_for_category)}) '{articulo_para_resumir['titulo']}' de {articulo_para_resumir['source_name']}...")
            if not articulo_para_resumir["link"] or articulo_para_resumir["link"] == "[sin link]":
                print(f"    ‚ö†Ô∏è Saltando art√≠culo con enlace faltante: {articulo_para_resumir['titulo']}")
                continue
            contenido = extraer_contenido(articulo_para_resumir["link"])
            if not contenido:
                print(f"    ‚ö†Ô∏è No se pudo extraer contenido de: {articulo_para_resumir['link']}")
                continue
            time.sleep(1.5)
            datos_gemini = resumir_y_puntuar_con_gemini(gemini_model, articulo_para_resumir["titulo"], contenido, categoria)
            if datos_gemini and \
               datos_gemini.get("teaser_sentence") and \
               datos_gemini.get("resumen") and isinstance(datos_gemini.get("relevancia_score"), int):
                articulos_procesados_final_categoria.append({
                    "info": articulo_para_resumir,
                    "resumen_datos": datos_gemini
                })
                any_article_processed_overall = True
            else:
                print(f"    ‚ö†Ô∏è Gemini no devolvi√≥ datos v√°lidos para: {articulo_para_resumir['titulo']}")
        articulos_procesados_final_categoria.sort(key=lambda x: x["resumen_datos"].get("relevancia_score", 0), reverse=True)
        processed_articles_by_category[categoria] = articulos_procesados_final_categoria

    report_type = "Semanal" if horas_a_revisar == DEFAULT_WEEKLY_HOURS else "Diario"

    # Determinar el nombre del archivo de salida seg√∫n el tipo de reporte
    if report_type == "Semanal":
        output_html_file_name = "resumen_semanal.html"
    else:
        # Usar index.html para el reporte diario para que sea la p√°gina principal del sitio
        output_html_file_name = "index.html"
    output_html_file_path = os.path.join(SCRIPT_DIR, output_html_file_name)

    # Obtener la fecha y hora actual para el timestamp
    generation_timestamp = datetime.now(timezone.utc)
    generation_timestamp_str = generation_timestamp.strftime("%d de %B de %Y, %H:%M:%S UTC")
    html_content = generate_html_content(processed_articles_by_category, report_type, generation_timestamp_str)
    if not any_article_processed_overall:
        print("‚ÑπÔ∏è No se proces√≥ ning√∫n art√≠culo para el resumen final.")

    try:
        with open(output_html_file_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        full_web_url = BASE_WEB_URL + output_html_file_name
        print(f"üìÑ Resumen {report_type} interactivo guardado en: {output_html_file_path}")

        # Ya no se usa SCP, la subida la hace GitHub Actions a GitHub Pages
        print(f"‚ÑπÔ∏è  El archivo se desplegar√° en GitHub Pages: {full_web_url}")

        email_subject = f"Resumen {report_type} de Noticias Interactivo"        
        if not any_article_processed_overall:
            email_subject += " (Sin art√≠culos nuevos)"

        email_body = f"""
        Hola,

        Tu resumen de noticias {report_type.lower()} est√° listo.
        Puedes verlo directamente en GitHub Pages: {full_web_url}
        """
        email_body += """

        Saludos,
        Tu Compilador de Noticias
        """
        enviar_correo_con_enlace(email_subject, email_body)

    except IOError as e:
        print(f"‚ùå Error al guardar el archivo HTML: {e}")

# def subir_archivo_con_scp(archivo_local, usuario_remoto, host_remoto, ruta_remota_base, nombre_archivo_remoto):
#     ruta_completa_remota_destino = f"{ruta_remota_base}/{nombre_archivo_remoto}"
#     comando_scp = [
#         "scp",
#         "-o", "BatchMode=yes",
#         "-o", "ConnectTimeout=10",
#         archivo_local,
#         f"{usuario_remoto}@{host_remoto}:{ruta_completa_remota_destino}"
#     ]
#     try:
#         print(f"üöÄ Intentando subir {archivo_local} a {host_remoto}...")
#         print(f"   Comando: {' '.join(comando_scp)}")
#         proceso = subprocess.run(comando_scp, check=True, capture_output=True, text=True, timeout=60)
#         print(f"‚úÖ Archivo subido exitosamente a {host_remoto}:{ruta_completa_remota_destino}")
#         if proceso.stdout: print(f"   Salida de SCP (stdout): {proceso.stdout.strip()}")
#         if proceso.stderr: print(f"   Salida de SCP (stderr): {proceso.stderr.strip()}")
#         return True
#     except subprocess.CalledProcessError as e:
#         print(f"‚ùå Error al subir archivo con SCP (C√≥digo de retorno: {e.returncode}):")
#         if e.stdout: print(f"   Salida Est√°ndar: {e.stdout.strip()}")
#         if e.stderr: print(f"   Salida de Error: {e.stderr.strip()}")
#         return False
#     except FileNotFoundError:
#         print("‚ùå Error: El comando 'scp' no se encontr√≥. Aseg√∫rate de que est√© instalado y en tu PATH.")
#         return False
#     except subprocess.TimeoutExpired:
#         print("‚ùå Error: El comando SCP tard√≥ demasiado tiempo (timeout).")
#         return False

def enviar_correo_con_enlace(subject, body_text):
    remitente = os.getenv("GMAIL_USER", "tu_email@gmail.com") # Lee de variable de entorno o usa un default
    destinatario = os.getenv("GMAIL_DESTINATARIO", remitente) # Lee de variable o env√≠a a remitente
    
    gmail_app_password = os.getenv("GMAIL_APP_PASSWORD")
    if not gmail_app_password:
        print("‚ùå Error: La variable de entorno GMAIL_APP_PASSWORD no est√° configurada. No se puede enviar correo.")
        return
    if not remitente or remitente == "tu_email@gmail.com":
        print("‚ùå Error: La variable de entorno GMAIL_USER no est√° configurada o usa el valor por defecto. No se puede enviar correo.")
        return


    msg = MIMEText(body_text)
    msg["Subject"] = subject
    msg["From"] = remitente
    msg["To"] = destinatario

    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
            server.login(remitente, gmail_app_password)
            server.sendmail(remitente, destinatario, msg.as_string())
            print("üìß Correo con enlace enviado exitosamente.")
    except Exception as e:
        print(f"‚ùå Error al enviar correo con enlace: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Compila, resume y punt√∫a noticias de feeds RSS.")
    parser.add_argument(
        "-w", "--weekly", action="store_true",
        help=f"Genera un reporte semanal (√∫ltimas {DEFAULT_WEEKLY_HOURS} horas) en lugar del reporte diario (√∫ltimas {DEFAULT_HOURS_AGO} horas)."
    )
    args = parser.parse_args()

    horas_a_revisar = DEFAULT_WEEKLY_HOURS if args.weekly else DEFAULT_HOURS_AGO
    report_type_str = "Semanal" if args.weekly else "Diario"
    print(f"üöÄ Iniciando compilador de noticias para el reporte {report_type_str} (√∫ltimas {horas_a_revisar} horas).")

    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        print("‚ùå Error CR√çTICO: La variable de entorno GEMINI_API_KEY no est√° configurada.")
        exit(1)

    try:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_generative_model = genai.GenerativeModel(
            'gemini-1.5-flash-latest',
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=450,
                temperature=0.5,
                response_mime_type="application/json"
            )
        )
        print("‚úÖ Modelo Gemini inicializado correctamente.")
    except Exception as e:
        print(f"‚ùå Error CR√çTICO al inicializar el modelo de Gemini: {e}")
        exit(1)

    fuentes = cargar_fuentes_desde_json()
    procesar_y_resumir_articulos(fuentes, gemini_generative_model, horas_a_revisar)

# === INSTRUCCI√ìN IMPORTANTE ===
# Para que este script funcione correctamente, especialmente en entornos automatizados como GitHub Actions:
# 1. Aseg√∫rate de que el archivo 'fuentes_rss.json' est√© presente en el mismo directorio que este script.
# 2. Configura las siguientes variables de entorno (o "secrets" en GitHub Actions):
#    - GEMINI_API_KEY: Tu clave API de Google Gemini.
#    - GMAIL_APP_PASSWORD: Tu contrase√±a de aplicaci√≥n de Gmail.
#    - GMAIL_USER: Tu direcci√≥n de correo de Gmail (remitente).
#    - GMAIL_DESTINATARIO: (Opcional) Direcci√≥n de correo del destinatario, si es diferente al remitente.
#    - BASE_WEB_URL: (Autom√°ticamente provista por el workflow para GitHub Pages)
#    - GITHUB_REPOSITORY_OWNER: (Autom√°ticamente provista por el workflow)
#    - GITHUB_REPOSITORY_NAME: (Autom√°ticamente provista por el workflow)
# 
#  Variables de SCP ya no son necesarias si solo usas GitHub Pages:
#    - STANFORD_USER, STANFORD_HOST_SCP, STANFORD_REMOTE_PATH, STANFORD_SSH_PRIVATE_KEY
# Para desarrollo local, puedes crear un archivo '.env' en el mismo directorio y definir estas variables all√≠.
# La l√≠nea 'load_dotenv()' al principio del script cargar√° estas variables.
